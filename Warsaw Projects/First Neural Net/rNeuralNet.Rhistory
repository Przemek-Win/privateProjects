lines(density(CH$TotalCharges[CH$CH=="No"]), lwd=2, col="red")
legend("topright", c("CH=Yes", "CH=No"),
lty = 1, lwd = 2, col = c("black", "red"))
# zarowno MonthlyCharges jak i Tenure jest bardziej obiecujaca do objasniania CH
# niz TotalCharges --> usuniecie TotalCharges
CH <- within(CH, {
TotalCharges <- NULL
MultipleLines <- NULL
StreamingTV <- NULL
StreamingMovies <- NULL
OnlineSecurity <- NULL
OnlineBackup <- NULL
DeviceProtection <- NULL
TechSupport <- NULL
})
#PODZIAL ZBIORU
# wktor zawierajacy permutacje numerów wierszy:
random.numbers <- sample.int(nrow(CH))
# dzielimy zbior na trzy czesci
quantiles <- quantile(random.numbers, probs = c(0, 1/2, 2/3, 1))
split.labels <- cut(random.numbers, quantiles, include.lowest = TRUE,
labels = c("training", "test", "validation"))
split.data <- split(CH, split.labels)
zb_uczacy <- split.data$training
zb_walidacyjny <- split.data$validation
zb_testowy <- split.data$test
library('RcmdrPlugin.BCA')
# Budowa modelu maksimum
GLM.MAX <- glm(CH ~ ., family=binomial(logit), data=zb_uczacy)
summary(GLM.MAX)
# Redukcja zmiennych algorytmem WesStep
WES.STEP <- step(GLM.MAX, direction="both", k=2)
summary(WES.STEP)
# zmienne wybrane algorytmem stepwise:
# SeniorCitizen, Dependents, Tenure, PhoneService, InternetService, InternetService, Contract,
# PaperlessBilling, PaymentMethod, MonthlyCharges
SIEC.1 <- Nnet(CH ~ SeniorCitizen + Dependents + Tenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges
,data=zb_uczacy, size=4,decay=0.2)
summary(SIEC.1)
# porownanie modeli:
lift.chart(c("WES.STEP", "SIEC.1"),
zb_walidacyjny, "Yes", 0.26, "cumulative")
table(CH$CH) #0.26
# regresja z logarytmami
zb_uczacy$logTenure <- with(zb_uczacy, log(Tenure+1))
zb_uczacy$logMonthlyCharges <- with(zb_uczacy, log(MonthlyCharges+1))
zb_walidacyjny$logTenure <- with(zb_walidacyjny, log(Tenure+1))
zb_walidacyjny$logMonthlyCharges <- with(zb_walidacyjny, log(MonthlyCharges+1))
zb_testowy$logTenure <- with(zb_testowy, log(Tenure+1))
zb_testowy$logMonthlyCharges <- with(zb_testowy, log(MonthlyCharges+1))
GLM.2 <- glm(CH ~ SeniorCitizen + Dependents + logTenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + logMonthlyCharges
,family=binomial(logit), data=zb_uczacy)
summary(GLM.2)
lift.chart(c("GLM.2", "SIEC.1"),
zb_walidacyjny, "Yes", 0.26, "cumulative")
#regresja rownie dobra jak siec --> model GLM.2
lift.chart("GLM.2",
zb_testowy, "Yes", 0.26, "cumulative")
SIEC.2 <- Nnet(CH ~ SeniorCitizen + Dependents + logTenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + logMonthlyCharges
,data=zb_uczacy, size=4,decay=0.2)
summary(SIEC.1)
# porownanie modeli:
lift.chart(c("GLM.2", "SIEC.2"),
zb_walidacyjny, "Yes", 0.26, "cumulative")
setwd("C:/Users/Tom/Documents/Semestr letni 2015-2016/Bigdata/")
CH <- read.csv("Churn.csv")
CH <- within(CH, {
customerID <- NULL
})
#wszystko z dużej litery
colnames(CH)[1] <- "Gender"
colnames(CH)[5] <- "Tenure"
CH <- read.csv("Churn.csv")
setwd("C:/Users/Tom/Documents/Semestr letni 2015-2016/Bigdata/Przemek/")
CH <- read.csv("Churn.csv")
CH <- within(CH, {
customerID <- NULL
})
#wszystko z dużej litery
colnames(CH)[1] <- "Gender"
colnames(CH)[5] <- "Tenure"
#imputacja z wykorzystaniem sredniej dla danej kolumny
CH$TotalCharges <- impute(CH$TotalCharges,mean)
CH_notnumeric <- CH[,-c(5,18,19)]
CH_numeric <- CH[,c(5,18,19)]
c <- colnames(CH_notnumeric)
pdf("C:/Users/Renata/Desktop/big data/Rapid Model Development Framework/CH/wykresy2.pdf")
for (i in 1:16) {
itemID <-i
zmienna <- c[i]
table <- table(CH_notnumeric$CH, CH_notnumeric[,i])
mosaicplot(table ,main= paste("CH ~", zmienna),
xlab="CH",ylab=zmienna,
col=grey.colors(4, start = 0.9, end = 0.3, gamma = 2.2, alpha = NULL))
}
dev.off()
#analiza wykresow:
#Gender, PhoneService nic nie wnosz¹ do objasniania CH
cor(CH_numeric,
use="complete")
# Tenure ~ TotalCharges 0.82
# MonthlyCharges ~ TotalCharges 0.65
plot(CH$MonthlyCharges, CH$TotalCharges)
plot(CH$Tenure, CH$TotalCharges)
plot(density(CH$MonthlyCharges[CH$CH=="Yes"]), lwd=2, main="Gętość warunkowa dla MonthlyCharges", xlab="MonthlyCharges", ylab="gêstoæ")
lines(density(CH$MonthlyCharges[CH$CH=="No"]), lwd=2, col="red")
legend("topright", c("CH=Yes", "CH=No"),
lty = 1, lwd = 2, col = c("black", "red"))
plot(density(CH$Tenure[CH$CH=="Yes"]), lwd=2, main="Gęstość warunkowa dla Tenure", xlab="Tenure", ylab="gêstoæ")
lines(density(CH$Tenure[CH$CH=="No"]), lwd=2, col="red")
legend("topright", c("CH=Yes", "CH=No"),
lty = 1, lwd = 2, col = c("black", "red"))
plot(density(CH$TotalCharges[CH$CH=="Yes"]), lwd=2, main="Gęstość warunkowa dla TotalCharges", xlab="TotalCharges", ylab="gêstoæ")
lines(density(CH$TotalCharges[CH$CH=="No"]), lwd=2, col="red")
legend("topright", c("CH=Yes", "CH=No"),
lty = 1, lwd = 2, col = c("black", "red"))
# zarowno MonthlyCharges jak i Tenure jest bardziej obiecujaca do objasniania CH
# niz TotalCharges --> usuniecie TotalCharges
CH <- within(CH, {
TotalCharges <- NULL
MultipleLines <- NULL
StreamingTV <- NULL
StreamingMovies <- NULL
OnlineSecurity <- NULL
OnlineBackup <- NULL
DeviceProtection <- NULL
TechSupport <- NULL
})
#PODZIAL ZBIORU
# wktor zawierajacy permutacje numerów wierszy:
random.numbers <- sample.int(nrow(CH))
# dzielimy zbior na trzy czesci
quantiles <- quantile(random.numbers, probs = c(0, 1/2, 2/3, 1))
split.labels <- cut(random.numbers, quantiles, include.lowest = TRUE,
labels = c("training", "test", "validation"))
split.data <- split(CH, split.labels)
zb_uczacy <- split.data$training
zb_walidacyjny <- split.data$validation
zb_testowy <- split.data$test
library('RcmdrPlugin.BCA')
# Budowa modelu maksimum
GLM.MAX <- glm(CH ~ ., family=binomial(logit), data=zb_uczacy)
summary(GLM.MAX)
# Redukcja zmiennych algorytmem WesStep
WES.STEP <- step(GLM.MAX, direction="both", k=2)
summary(WES.STEP)
# zmienne wybrane algorytmem stepwise:
# SeniorCitizen, Dependents, Tenure, PhoneService, InternetService, InternetService, Contract,
# PaperlessBilling, PaymentMethod, MonthlyCharges
SIEC.1 <- Nnet(CH ~ SeniorCitizen + Dependents + Tenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges
,data=zb_uczacy, size=4,decay=0.2)
summary(SIEC.1)
# porownanie modeli:
lift.chart(c("WES.STEP", "SIEC.1"),
zb_walidacyjny, "Yes", 0.26, "cumulative")
table(CH$CH) #0.26
# regresja z logarytmami
zb_uczacy$logTenure <- with(zb_uczacy, log(Tenure+1))
zb_uczacy$logMonthlyCharges <- with(zb_uczacy, log(MonthlyCharges+1))
zb_walidacyjny$logTenure <- with(zb_walidacyjny, log(Tenure+1))
zb_walidacyjny$logMonthlyCharges <- with(zb_walidacyjny, log(MonthlyCharges+1))
zb_testowy$logTenure <- with(zb_testowy, log(Tenure+1))
zb_testowy$logMonthlyCharges <- with(zb_testowy, log(MonthlyCharges+1))
GLM.2 <- glm(CH ~ SeniorCitizen + Dependents + logTenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + logMonthlyCharges
,family=binomial(logit), data=zb_uczacy)
summary(GLM.2)
lift.chart(c("GLM.2", "SIEC.1"),
zb_walidacyjny, "Yes", 0.26, "cumulative")
#regresja rownie dobra jak siec --> model GLM.2
lift.chart("GLM.2",
zb_testowy, "Yes", 0.26, "cumulative")
SIEC.2 <- Nnet(CH ~ SeniorCitizen + Dependents + logTenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + logMonthlyCharges
,data=zb_uczacy, size=4,decay=0.2)
summary(SIEC.1)
# porownanie modeli:
lift.chart(c("GLM.2", "SIEC.2"),
zb_walidacyjny, "Yes", 0.26, "cumulative")
install.packages("RcmdrPlugin.BCA")
library(RcmdrPlugin.BCA)
GLM.MAX <- glm(CH ~ ., family=binomial(logit), data=zb_uczacy)
summary(GLM.MAX)
# Redukcja zmiennych algorytmem WesStep
WES.STEP <- step(GLM.MAX, direction="both", k=2)
summary(WES.STEP)
# zmienne wybrane algorytmem stepwise:
# SeniorCitizen, Dependents, Tenure, PhoneService, InternetService, InternetService, Contract,
# PaperlessBilling, PaymentMethod, MonthlyCharges
SIEC.1 <- Nnet(CH ~ SeniorCitizen + Dependents + Tenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges
,data=zb_uczacy, size=4,decay=0.2)
summary(SIEC.1)
# porownanie modeli:
lift.chart(c("WES.STEP", "SIEC.1"),
zb_walidacyjny, "Yes", 0.26, "cumulative")
table(CH$CH) #0.26
# regresja z logarytmami
zb_uczacy$logTenure <- with(zb_uczacy, log(Tenure+1))
zb_uczacy$logMonthlyCharges <- with(zb_uczacy, log(MonthlyCharges+1))
zb_walidacyjny$logTenure <- with(zb_walidacyjny, log(Tenure+1))
zb_walidacyjny$logMonthlyCharges <- with(zb_walidacyjny, log(MonthlyCharges+1))
zb_testowy$logTenure <- with(zb_testowy, log(Tenure+1))
zb_testowy$logMonthlyCharges <- with(zb_testowy, log(MonthlyCharges+1))
GLM.2 <- glm(CH ~ SeniorCitizen + Dependents + logTenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + logMonthlyCharges
,family=binomial(logit), data=zb_uczacy)
summary(GLM.2)
lift.chart(c("GLM.2", "SIEC.1"),
zb_walidacyjny, "Yes", 0.26, "cumulative")
#regresja rownie dobra jak siec --> model GLM.2
lift.chart("GLM.2",
zb_testowy, "Yes", 0.26, "cumulative")
SIEC.2 <- Nnet(CH ~ SeniorCitizen + Dependents + logTenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + logMonthlyCharges
,data=zb_uczacy, size=4,decay=0.2)
summary(SIEC.1)
# porownanie modeli:
lift.chart(c("GLM.2", "SIEC.2"),
zb_walidacyjny, "Yes", 0.26, "cumulative")
GLM.MAX <- glm(CH ~ ., family=binomial(logit), data=zb_uczacy)
summary(GLM.MAX)
GLM.MAX <- glm(chrun ~ ., family=binomial(logit), data=zb_uczacy)
GLM.MAX <- glm(churn ~ ., family=binomial(logit), data=zb_uczacy)
zb_uczacy
GLM.MAX <- glm(Churn ~ ., family=binomial(logit), data=zb_uczacy)
summary(GLM.MAX)
WES.STEP <- step(GLM.MAX, direction="both", k=2)
summary(WES.STEP)
netw.1 <- Nnet(Chrun ~ SeniorCitizen + Dependents + Tenure + PhoneService + InternetService +
netw.1 <- Nnet(Chrun ~ SeniorCitizen + Dependents + Tenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges
,data=zb_uczacy, size=4,decay=0.2)
summary(netw.1)
netw.1 <- Nnet(Chrun ~ SeniorCitizen + Dependents + Tenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges
,data=zb_uczacy, size=4,decay=0.2)
summary(netw.1)
install.package("nnet")
library(nnet)
netw.1 <- Nnet(Chrun ~ SeniorCitizen + Dependents + Tenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges
,data=zb_uczacy, size=4,decay=0.2)
library(nnet)
netw.1 <- Nnet(Chrun ~ SeniorCitizen + Dependents + Tenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges
,data=zb_uczacy, size=4,decay=0.2)
require(nnet)
netw.1 <- Nnet(Chrun ~ SeniorCitizen + Dependents + Tenure + PhoneService + InternetService +
InternetService + Contract + PaperlessBilling + PaymentMethod + MonthlyCharges
,data=zb_uczacy, size=4,decay=0.2)
setwd("C:/Users/Tom/Documents/R")
alan<-read.csv("production.csv")
head(alan)
head(alan[,1:12])
head(alan[,1:15])
head(alan[,1:18])
head(alan[,1:20])
head(alan[,1:21])
head(alan[,1:20])
head(alan[,3:20])
head(alan[,5:20])
zbior<-(alan[,5:20])
data.set<-(alan[,5:20])
mode(data.set)
str(data.set)
dim(data.set)
summary(data.set)
str(data.set)
colMeans(data.set) #srednia wartosc
data.set[,15]
levels(data.set[,15])
as.numeric(levels(data.set[,15]))[data.set[,15]]
as.numeric(levels(data.set[,15]))
levels(data.set[,15])
as.data.frame.factor(data.set[,15])
as.integer(data.set[,15])
as.integer(data.set[,14])
as.integer(data.set[,13])
as.integer(data.set[,12])
as.integer(data.set[,11])
data.set[,11]
as.integer(data.set[,10])
data.set[,10]
data.set
head(data.set)
as.integer(data.set[,9])
head(data.set)
as.integer(data.set[,11:18])
data<-data.set
for (i in 11:18){
data[,i]<-as.integer(data.set[,i])
}
for (i in 11:17){
data[,i]<-as.integer(data.set[,i])
}
as.integer(data.set[,17])
for (i in 11:16){
data[,i]<-as.integer(data.set[,i])
}
data
str(data)
data<-data[,-10]
str(data)
data.set<-data
colMeans(data.set) #srednia wartosc
for (i in 1:length[data.set[,2]]){
if (data.set[i,2]<0.5) {
data.set[i,2]=0
}
else {
data.set[i,2]=1
}
}
length[data.set[,2]]
data.set[,2]
dim(data.set)
for (i in 1:119081){
if (data.set[i,2]<0.5) {
data.set[i,2]=0
}
else {
data.set[i,2]=1
}
}
summary(data.set)
baza<-data.set[,2]
colMeans(data.set) #srednia wartosc
sapply(data.set,sd) #odchylenie standardowe
scaled.data<-scale(data.set[-2]) #standaryzacja zmiennych bez zmiennej objanianej
final.data<-cbind(scaled.data,data.set[2])
dim(final.data)
train.part<-valid.part<-0.4
random.numbers<-sample.int(2)
quantiles<-quantile(random.numbers,prob=c(0,train.part,train.part+valid.part,1))
split.labels<-cut(random.numbers,quantiles,include.lowest=T,labels=c("train","valid","test"))
data<-split(final.data,split.labels)
train.part<-valid.part<-0.4
random.numbers<-sample.int(nrow(final.data))
quantiles<-quantile(random.numbers,prob=c(0,train.part,train.part+valid.part,1))
split.labels<-cut(random.numbers,quantiles,include.lowest=T,labels=c("train","valid","test"))
data<-split(final.data,split.labels)
str(data)
is.list(data)
neurons<-5 #ile neuronow w wartstwie ukrytej
decays<-seq(0,40,length=100) #paramet wagi dla kary/wspolczynnik regularyzacji
wts.parameter<-2*runif(5*ncol(final.data)+neurons+1)-1 #poczatkowe wartosci wag dla sieci
train.error<-valid.error<-numeric(length(decays)) #obikety bledow odpowiednio dla zbioru testujace i walidacyjnego
neural.nets<-list()
progress.bar<-winProgressBar("Postep w %","0% zrobione",0,1,0)
for (d in 1:length(decays)) {
neural.nets[[d]]<-nnet(act_cc~.,data=data$train,size=neurons,decay=decays[d],linout=T,maxit=10000,trace=FALSE,Wts=wts.parameter)
train.error[d]<-mean(neural.nets[[d]]$residuals^2)
prediction<-predict(neural.nets[[d]],newdata=data$valid)
valid.error[d]<-mean((prediction-data$valid$MEDV)^2)
percentage<-d/length(decays)
setWinProgressBar(progress.bar,percentage,"Postep w %",sprintf("%d%% zrobione",round(100*percentage)))
}
close(progress.bar)
#wybór najlepszego modelu sieci neuronowej
best.neural.net<-neural.nets[[which.min(valid.error)]]
test.prediction<-predict(best.neural.net,newdata=data$test)
best.net.test.error<-mean((test.prediction-data$test$MEDV)^2)
neurons<-5 #ile neuronow w wartstwie ukrytej
decays<-seq(0,40,length=100) #paramet wagi dla kary/wspolczynnik regularyzacji
wts.parameter<-2*runif(5*ncol(final.data)+neurons+1)-1 #poczatkowe wartosci wag dla sieci
train.error<-valid.error<-numeric(length(decays)) #obikety bledow odpowiednio dla zbioru testujace i walidacyjnego
neural.nets<-list()
progress.bar<-winProgressBar("Postep w %","0% zrobione",0,1,0)
for (d in 1:length(decays)) {
neural.nets[[d]]<-nnet(act_cc~.,data=data$train,size=neurons,decay=decays[d],linout=T,maxit=10000,trace=FALSE,Wts=wts.parameter)
train.error[d]<-mean(neural.nets[[d]]$residuals^2)
prediction<-predict(neural.nets[[d]],newdata=data$valid)
valid.error[d]<-mean((prediction-data$valid$act_cc)^2)
percentage<-d/length(decays)
setWinProgressBar(progress.bar,percentage,"Postep w %",sprintf("%d%% zrobione",round(100*percentage)))
}
close(progress.bar)
#wybór najlepszego modelu sieci neuronowej
best.neural.net<-neural.nets[[which.min(valid.error)]]
test.prediction<-predict(best.neural.net,newdata=data$test)
best.net.test.error<-mean((test.prediction-data$test$MEDV)^2)
best.neural.net<-neural.nets[[which.min(valid.error)]]
test.prediction<-predict(best.neural.net,newdata=data$test)
best.net.test.error<-mean((test.prediction-data$test$act_cc)^2)
library(clusterGeneration)
library(devtools)
source('http://akson.sgh.waw.pl/~d10a2014/pliki/SRD/nnet_plot_update.R')
plot.nnet(best.neural.net$wts,struct=best.neural.net$n,bias=TRUE)
names(best.neural.net)
best.neural.net$n #struktura
best.neural.net$wts #wagi w poszczególnych neuronach
summary(best.neural.net)
nn.mlp<-mlp(data$train[,-ncol(data$train)],data$train[,ncol(data$train)],size=c(2,2),maxit=50)
summary(nn.mlp)
names(nn.mlp)
nn.mlp$fitted.values
nn.mlp
weightMatrix(nn.mlp)
extractNetInfo(nn.mlp)
library(RSNNS)
install.packages("RSNNS")
library(RSNNS)
nn.mlp<-mlp(data$train[,-ncol(data$train)],data$train[,ncol(data$train)],size=c(2,2),maxit=50)
summary(nn.mlp)
names(nn.mlp)
nn.mlp$fitted.values
nn.mlp
weightMatrix(nn.mlp)
extractNetInfo(nn.mlp)
head(data.set)
head(alan[,5:20])
str(alan[,5:20])
head(data.set)
head(alan[,5:20])
str(alan[,5:20])
levels(alan[,5:20])
levels(alan[,5:20]$app_char_city)
head(alan[,5:20])
head(data.set)
levels(alan[,5:20]$app_char_marital_status)
levels(alan[,5:20]$app_char_job_code)
levels(alan[,5:20]$app_char_gender)
levels(alan[,5:20]$app_char_branch)
install.packages("neuralnet")
library(neuralnet)
formula<-eval(paste("act_cc~",paste(names(data$train[-13]),collapse="+")))
set.seed(2)
nn<-neuralnet(formula,data=data$train,rep=2,hidden=c(neurons,2),stepmax=1e+06)
plot(nn,rep="best",fontsize=10,show.weights=FALSE)
summary(nn)
nn$weights # wagi dla wszystkich neuronów
confidence.interval(nn,alpha=0.05) #przedziały ufnoci dla wag w sieci neuronowej oraz Network Information Criterion (NIC)
gwplot(nn) #wykres wszystkich wag dla wybranej zmiennej
formula<-eval(paste("act_cc~",paste(names(data$train[-13]),collapse="+")))
set.seed(2)
nn<-neuralnet(formula,data=data$train,rep=2,hidden=c(neurons,2),stepmax=1e+06)
data$train
formula<-eval(paste("act_cc~",paste(names(data$train[-14]),collapse="+")))
nn<-neuralnet(formula,data=data$train,rep=2,hidden=c(neurons,2),stepmax=1e+06)
?neuralnet
nn<-neuralnet(act_cc~.,data=data$train,rep=2)
str(data$train)
nn<-neuralnet(act_cc~app_char_cars+app_char_hom_status,data=data$train,rep=2)
nn<-neuralnet(act_cc~app_char_cars+app_char_home_status,data=data$train,rep=2)
plot(nn,rep="best",fontsize=10,show.weights=FALSE)
nn<-neuralnet(act_cc~app_char_cars+app_char_home_status,data=data$train,rep=2,hidden=c(neurons,2))
nn<-neuralnet(act_cc~app_char_cars+app_char_home_status+app_char_city+app_char_martial_status+app_char_job_code+app_char_gender+app_installment+app_spendings+app_number_of_children+app_n_installments+app_loan_amount+app_income+act_age,data=data$train,rep=2,hidden=c(neurons,2))
nn<-neuralnet(act_cc~app_char_cars+app_char_home_status+app_char_city+app_char_marital_status+app_char_job_code+app_char_gender+app_installment+app_spendings+app_number_of_children+app_n_installments+app_loan_amount+app_income+act_age,data=data$train,rep=2,hidden=c(neurons,2))
nn<-neuralnet(act_cc~app_char_cars+app_char_home_status+app_char_city+app_char_marital_status+app_char_job_code+app_char_gender+app_installment+app_spendings+app_number_of_children+app_n_installments+app_loan_amount+app_income+act_age,data=data$train,rep=2,hidden=c(neurons,2))
neural.nets
best.neural.net
best.neural.net$n
?plot.nnet
best.neural.net$wts
plot.nnet(best.neural.net,struct=best.neural.net$n,bias=TRUE)
iris3
ir<-rbind(iris3[,,1],iris3[,,2],iris3[,,3])
targets<-class.ind( c(rep("s", 50), rep("c", 50), rep("v", 50)) )
samp<-c(sample(1:50,25), sample(51:100,25), sample(101:150,25))
ir1<-nnet(ir[samp,], targets[samp,], size = 2, rang = 0.1,decay = 5e-4, maxit = 200)
#plot the model with different default values for the arguments
par(mar=numeric(4),family='serif')
plot.nnet(ir1,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.7,rel.rsc=15,
circle.cex=10,cex=1.4,
circle.col='brown')
ir1
install.package("reshape")
install.packages("reshape")
library(reshape)
ir<-rbind(iris3[,,1],iris3[,,2],iris3[,,3])
targets<-class.ind( c(rep("s", 50), rep("c", 50), rep("v", 50)) )
samp<-c(sample(1:50,25), sample(51:100,25), sample(101:150,25))
ir1<-nnet(ir[samp,], targets[samp,], size = 2, rang = 0.1,decay = 5e-4, maxit = 200)
#plot the model with different default values for the arguments
par(mar=numeric(4),family='serif')
plot.nnet(ir1,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.7,rel.rsc=15,
circle.cex=10,cex=1.4,
circle.col='brown')
ir1
ir
best.neural.net
plot.nnet(best.neural.net,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.7,rel.rsc=15,
circle.cex=10,cex=1.4,
circle.col='brown')
plot.nnet(best.neural.net,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.7,rel.rsc=15,
circle.cex=4,cex=1.4,
circle.col='grey')
plot.nnet(best.neural.net,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.7,rel.rsc=15,
circle.cex=4,cex=0.8,
circle.col='grey')
plot.nnet(best.neural.net,pos.col='darkgreen',neg.col='darkblue',alpha.val=1,rel.rsc=15,
circle.cex=4,cex=0.8,
circle.col='grey')
plot.nnet(best.neural.net,pos.col='darkgreen',neg.col='darkblue',alpha.val=1,rel.rsc=10,
circle.cex=4,cex=0.8,
circle.col='grey')
best.net.test.error<-mean((test.prediction-data$test$act_cc)^2)
best.net.test.error
best.neural.net2<-neural.nets[[which.max(valid.error)]]
test.prediction2<-predict(best.neural.net2,newdata=data$test)
best.net.test.error2<-mean((test.prediction2-data$test$act_cc)^2)
worst.net.test.error2<-mean((test.prediction2-data$test$act_cc)^2)
worst.net.test.error2
colMeans(data.set) #srednia wartosc
write.csv(data.set, file="zbiorpw57135.csv")
setwd("C:/Users/Tom/Documents/Semestr letni 2015-2016/Sztuczna Inteligencja")
write.csv(data.set, file="zbiorpw57135.csv")
